#!/usr/bin/env python3
"""
è°ƒè¯•è„šæœ¬ï¼šæ£€æŸ¥RunPod Volumeä¸­çš„æ¨¡å‹æ–‡ä»¶ç»“æ„
æ‰¾å‡ºå¯¼è‡´ NoneType é”™è¯¯çš„ç¼ºå¤±æ–‡ä»¶
"""

import os
import json

def check_volume_structure():
    """æ£€æŸ¥Volumeä¸­çš„æ¨¡å‹æ–‡ä»¶ç»“æ„"""
    volume_path = "/runpod-volume/photonicfusion-sdxl"
    
    print(f"ğŸ” æ£€æŸ¥æ¨¡å‹ç›®å½•: {volume_path}")
    
    if not os.path.exists(volume_path):
        print("âŒ Volumeè·¯å¾„ä¸å­˜åœ¨!")
        return
    
    # æ£€æŸ¥å¿…éœ€çš„SDXLç»„ä»¶
    required_components = [
        "model_index.json",
        "unet",
        "vae", 
        "text_encoder",
        "text_encoder_2",
        "scheduler",
        "tokenizer",
        "tokenizer_2"
    ]
    
    print("\nğŸ“‹ æ£€æŸ¥å¿…éœ€ç»„ä»¶:")
    missing_components = []
    
    for component in required_components:
        component_path = os.path.join(volume_path, component)
        if os.path.exists(component_path):
            if os.path.isdir(component_path):
                files = os.listdir(component_path)
                print(f"âœ… {component}/ - {len(files)} ä¸ªæ–‡ä»¶")
                
                # æ£€æŸ¥å…³é”®é…ç½®æ–‡ä»¶
                config_file = os.path.join(component_path, "config.json")
                if os.path.exists(config_file):
                    print(f"   â””â”€â”€ config.json âœ…")
                else:
                    print(f"   â””â”€â”€ config.json âŒ")
                    missing_components.append(f"{component}/config.json")
                
                # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
                model_files = [f for f in files if f.endswith(('.safetensors', '.bin'))]
                if model_files:
                    print(f"   â””â”€â”€ æ¨¡å‹æ–‡ä»¶: {model_files}")
                else:
                    print(f"   â””â”€â”€ æ¨¡å‹æ–‡ä»¶: âŒ æœªæ‰¾åˆ°")
                    missing_components.append(f"{component}/model files")
            else:
                print(f"âœ… {component} - æ–‡ä»¶")
        else:
            print(f"âŒ {component} - ç¼ºå¤±")
            missing_components.append(component)
    
    # æ£€æŸ¥ model_index.json å†…å®¹
    model_index_path = os.path.join(volume_path, "model_index.json")
    if os.path.exists(model_index_path):
        print(f"\nğŸ“„ æ£€æŸ¥ model_index.json:")
        try:
            with open(model_index_path, 'r') as f:
                model_index = json.load(f)
            
            print(f"   æ¶æ„: {model_index.get('_class_name', 'Unknown')}")
            print(f"   ç»„ä»¶æ˜ å°„:")
            
            for key, value in model_index.items():
                if not key.startswith('_'):
                    if isinstance(value, list) and len(value) >= 2:
                        component_type, component_name = value[0], value[1] if value[1] else "null"
                        status = "âœ…" if component_name != "null" else "âŒ"
                        print(f"     {key}: {component_type} -> {component_name} {status}")
                        
                        if component_name == "null":
                            missing_components.append(f"model_index.json:{key}")
                            
        except Exception as e:
            print(f"   âŒ è¯»å–å¤±è´¥: {e}")
            missing_components.append("model_index.json (corrupt)")
    
    # æŸ¥æ‰¾FP16æ–‡ä»¶
    print(f"\nğŸ” æŸ¥æ‰¾FP16æ–‡ä»¶:")
    fp16_files = []
    for root, dirs, files in os.walk(volume_path):
        for file in files:
            if file.endswith('.fp16.safetensors'):
                rel_path = os.path.relpath(os.path.join(root, file), volume_path)
                fp16_files.append(rel_path)
    
    if fp16_files:
        print(f"âœ… æ‰¾åˆ° {len(fp16_files)} ä¸ªFP16æ–‡ä»¶:")
        for fp16_file in fp16_files:
            print(f"   - {fp16_file}")
    else:
        print("âŒ æœªæ‰¾åˆ°FP16æ–‡ä»¶")
    
    # æ€»ç»“
    print(f"\nğŸ“Š æ£€æŸ¥æ€»ç»“:")
    if missing_components:
        print(f"âŒ å‘ç° {len(missing_components)} ä¸ªé—®é¢˜:")
        for issue in missing_components:
            print(f"   - {issue}")
    else:
        print("âœ… æ‰€æœ‰å¿…éœ€ç»„ä»¶éƒ½å­˜åœ¨")
    
    return missing_components

def create_missing_configs():
    """åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶"""
    volume_path = "/runpod-volume/photonicfusion-sdxl"
    
    # æ ‡å‡†SDXLé…ç½®æ¨¡æ¿
    configs = {
        "tokenizer/tokenizer_config.json": {
            "add_prefix_space": False,
            "bos_token": {"__type": "AddedToken", "content": "<|startoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "clean_up_tokenization_spaces": True,
            "do_lower_case": True,
            "eos_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "errors": "replace",
            "model_max_length": 77,
            "name_or_path": "openai/clip-vit-large-patch14",
            "pad_token": "<|endoftext|>",
            "tokenizer_class": "CLIPTokenizer",
            "unk_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False}
        },
        
        "tokenizer_2/tokenizer_config.json": {
            "add_prefix_space": False,
            "bos_token": {"__type": "AddedToken", "content": "<|startoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "clean_up_tokenization_spaces": True,
            "do_lower_case": True,
            "eos_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "errors": "replace",
            "model_max_length": 77,
            "name_or_path": "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k",
            "pad_token": "<|endoftext|>",
            "tokenizer_class": "CLIPTokenizer",
            "unk_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False}
        }
    }
    
    print("ğŸ”§ åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶:")
    
    for config_path, config_content in configs.items():
        full_path = os.path.join(volume_path, config_path)
        
        if not os.path.exists(full_path):
            os.makedirs(os.path.dirname(full_path), exist_ok=True)
            
            with open(full_path, 'w') as f:
                json.dump(config_content, f, indent=2)
            
            print(f"âœ… åˆ›å»º: {config_path}")
        else:
            print(f"â­ï¸  å·²å­˜åœ¨: {config_path}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è°ƒè¯•Volumeç»“æ„...")
    
    missing = check_volume_structure()
    
    if missing:
        print(f"\nğŸ”§ å°è¯•ä¿®å¤ç¼ºå¤±çš„é…ç½®...")
        create_missing_configs()
        
        print(f"\nğŸ”„ é‡æ–°æ£€æŸ¥...")
        check_volume_structure()
    
    print(f"\nâœ… è°ƒè¯•å®Œæˆ!") 