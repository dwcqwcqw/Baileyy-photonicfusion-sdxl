#!/usr/bin/env python3
"""
åˆ é™¤æ ‡å‡†æ–‡ä»¶ï¼Œåªä¿ç•™FP16ç‰ˆæœ¬ï¼Œç„¶åé‡æ–°ä¸Šä¼ åˆ°HuggingFace
è¿™å°†èŠ‚çœçº¦ä¸€åŠçš„å­˜å‚¨ç©ºé—´
"""

import os
import shutil
from pathlib import Path

def delete_standard_files():
    """åˆ é™¤æ ‡å‡†æ–‡ä»¶ï¼Œåªä¿ç•™FP16ç‰ˆæœ¬"""
    
    model_path = "PhotonicFusionSDXL_V3-diffusers-manual"
    
    print("ğŸ—‘ï¸ PhotonicFusion SDXL æ ‡å‡†æ–‡ä»¶æ¸…ç†å™¨")
    print("=" * 50)
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        return False
    
    # è¦åˆ é™¤çš„æ ‡å‡†æ–‡ä»¶ï¼ˆä¿ç•™FP16ç‰ˆæœ¬ï¼‰
    files_to_delete = [
        "text_encoder/model.safetensors",
        "text_encoder_2/model.safetensors", 
        "unet/diffusion_pytorch_model.safetensors",
        "vae/diffusion_pytorch_model.safetensors"
    ]
    
    print("\nğŸ” åˆ é™¤æ ‡å‡†æ–‡ä»¶...")
    
    total_deleted_size = 0
    deleted_count = 0
    
    for file_path in files_to_delete:
        full_path = os.path.join(model_path, file_path)
        if os.path.exists(full_path):
            file_size = os.path.getsize(full_path)
            size_mb = file_size / (1024 * 1024)
            
            # åˆ é™¤æ–‡ä»¶
            os.remove(full_path)
            
            total_deleted_size += file_size
            deleted_count += 1
            
            print(f"   âœ… å·²åˆ é™¤: {file_path} ({size_mb:.1f} MB)")
        else:
            print(f"   âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    print(f"\nğŸ“Š åˆ é™¤ç»Ÿè®¡:")
    print(f"   å·²åˆ é™¤æ–‡ä»¶æ•°: {deleted_count}")
    print(f"   èŠ‚çœç©ºé—´: {total_deleted_size / (1024**3):.2f} GB")
    
    # éªŒè¯å‰©ä½™çš„FP16æ–‡ä»¶
    print("\nğŸ” éªŒè¯å‰©ä½™çš„FP16æ–‡ä»¶...")
    
    remaining_files = [
        "model_index.json",
        "text_encoder/model.fp16.safetensors",
        "text_encoder_2/model.fp16.safetensors",
        "unet/config.json",
        "unet/diffusion_pytorch_model.fp16.safetensors",
        "vae/config.json",
        "vae/diffusion_pytorch_model.fp16.safetensors",
        "scheduler/scheduler_config.json"
    ]
    
    remaining_size = 0
    missing_files = []
    
    for file_path in remaining_files:
        full_path = os.path.join(model_path, file_path)
        if os.path.exists(full_path):
            file_size = os.path.getsize(full_path)
            size_mb = file_size / (1024 * 1024)
            remaining_size += file_size
            
            file_type = "fp16" if "fp16" in file_path else "config"
            print(f"   âœ… {file_path} ({size_mb:.1f} MB) [{file_type}]")
        else:
            print(f"   âŒ {file_path}")
            missing_files.append(file_path)
    
    print(f"\nğŸ“Š å‰©ä½™æ–‡ä»¶æ€»å¤§å°: {remaining_size / (1024**3):.2f} GB")
    
    if missing_files:
        print(f"âŒ ç¼ºå°‘å¿…éœ€æ–‡ä»¶: {missing_files}")
        return False
    
    print("âœ… æ ‡å‡†æ–‡ä»¶åˆ é™¤å®Œæˆï¼ŒFP16ç‰ˆæœ¬å®Œæ•´ä¿ç•™")
    return True

def upload_to_huggingface_fp16_only():
    """ä¸Šä¼ åªåŒ…å«FP16ç‰ˆæœ¬çš„æ¨¡å‹åˆ°HuggingFace"""
    
    model_path = "PhotonicFusionSDXL_V3-diffusers-manual"
    repo_id = "Baileyy/photonicfusion-sdxl"
    
    print("\nğŸš€ ä¸Šä¼ FP16ä¼˜åŒ–ç‰ˆæœ¬åˆ°HuggingFace")
    print("=" * 40)
    
    # æ£€æŸ¥ huggingface_hub
    try:
        from huggingface_hub import HfApi, upload_folder, login
        print("âœ… huggingface_hub å¯ç”¨")
    except ImportError:
        print("âŒ huggingface_hub æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install huggingface_hub")
        return False
    
    # åˆ›å»ºä¼˜åŒ–çš„README
    readme_content = """---
license: apache-2.0
language:
- en
library_name: diffusers
pipeline_tag: text-to-image
tags:
- stable-diffusion-xl
- sdxl
- text-to-image
- diffusers
- fp16
---

# PhotonicFusion SDXL V3 (FP16 Optimized)

PhotonicFusion SDXL V3 æ˜¯ä¸€ä¸ªåŸºäº Stable Diffusion XL çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚

## æ¨¡å‹ç‰¹æ€§

- **æ¶æ„**: Stable Diffusion XL
- **åˆ†è¾¨ç‡**: 1024x1024 (åŸç”Ÿ)
- **ç²¾åº¦**: FP16 ä¼˜åŒ–ç‰ˆæœ¬ (èŠ‚çœ50%å­˜å‚¨ç©ºé—´)
- **ä¼˜åŒ–**: åªåŒ…å« FP16 variant æ–‡ä»¶ï¼Œæ›´å¿«çš„æ¨ç†é€Ÿåº¦

## æ–‡ä»¶ç»“æ„ (ä»…FP16ç‰ˆæœ¬)

æ­¤ç‰ˆæœ¬åªåŒ…å«FP16ä¼˜åŒ–æ–‡ä»¶ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´ï¼š

- `text_encoder/model.fp16.safetensors` (235MB)
- `text_encoder_2/model.fp16.safetensors` (1.3GB)
- `unet/diffusion_pytorch_model.fp16.safetensors` (4.8GB) 
- `vae/diffusion_pytorch_model.fp16.safetensors` (160MB)

**æ€»å¤§å°**: ~6.5GB (ç›¸æ¯”æ ‡å‡†ç‰ˆæœ¬èŠ‚çœ50%ç©ºé—´)

## ä½¿ç”¨æ–¹æ³•

### è‡ªåŠ¨FP16åŠ è½½ (æ¨è)
```python
from diffusers import StableDiffusionXLPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "Baileyy/photonicfusion-sdxl",
    torch_dtype=torch.float16,
    variant="fp16",  # ä½¿ç”¨ fp16 variant
    use_safetensors=True
)
pipeline.to("cuda")

# ç”Ÿæˆå›¾åƒ
image = pipeline(
    "a beautiful sunset over mountains, photorealistic", 
    height=1024, 
    width=1024,
    num_inference_steps=20
).images[0]
```

### åŸºç¡€åŠ è½½
```python
pipeline = StableDiffusionXLPipeline.from_pretrained(
    "Baileyy/photonicfusion-sdxl",
    torch_dtype=torch.float16,
    use_safetensors=True
)
```

## æ€§èƒ½ä¼˜åŠ¿

- **æ¨ç†é€Ÿåº¦**: 2-4 ç§’ (1024x1024, RTX 4090)
- **å†…å­˜éœ€æ±‚**: ~6-8GB VRAM (FP16 ä¼˜åŒ–)
- **å­˜å‚¨ç©ºé—´**: èŠ‚çœ50%ç£ç›˜ç©ºé—´
- **ä¸‹è½½é€Ÿåº¦**: æ›´å¿«çš„æ¨¡å‹ä¸‹è½½

## RunPod éƒ¨ç½²

æ­¤æ¨¡å‹å·²é’ˆå¯¹ RunPod Serverless éƒ¨ç½²è¿›è¡Œä¼˜åŒ–ï¼š
- Volume æŒ‚è½½ä¼˜åŒ–
- FP16 è‡ªåŠ¨åŠ è½½
- å†…å­˜æ•ˆç‡ä¼˜åŒ–
- å¿«é€Ÿå¯åŠ¨æ—¶é—´

éƒ¨ç½²ä»“åº“: [dwcqwcqw/Baileyy-photonicfusion-sdxl](https://github.com/dwcqwcqw/Baileyy-photonicfusion-sdxl)

## æ›´æ–°å†å²

### v3.0 (FP16 Optimized) - 2025-06-25
- ğŸ—‘ï¸ ç§»é™¤æ ‡å‡†safetensorsæ–‡ä»¶
- âœ… åªä¿ç•™FP16 variantæ–‡ä»¶
- ğŸš€ èŠ‚çœ50%å­˜å‚¨ç©ºé—´
- âš¡ ä¼˜åŒ–åŠ è½½æ€§èƒ½

### v2.0 (2025-06-25)
- âœ… æ·»åŠ  FP16 variant æ”¯æŒ
- âœ… ä¼˜åŒ–æ¨ç†æ€§èƒ½

### v1.0 (2025-06-24)
- åˆå§‹å‘å¸ƒ

## è®¸å¯è¯

Apache 2.0 License
"""
    
    # ä¿å­˜ä¼˜åŒ–çš„README
    readme_path = os.path.join(model_path, "README.md")
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print("âœ… åˆ›å»ºäº†FP16ä¼˜åŒ–ç‰ˆREADME.md")
    
    # ç™»å½•éªŒè¯
    print("\nğŸ” HuggingFace èº«ä»½éªŒè¯...")
    try:
        api = HfApi()
        user_info = api.whoami()
        print(f"âœ… å·²ç™»å½•ä¸º: {user_info['name']}")
    except Exception as e:
        print("âš ï¸ éœ€è¦ HuggingFace token")
        print("è¯·è¿è¡Œ: huggingface-cli login")
        return False
    
    # ä¸Šä¼ æ¨¡å‹
    print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ åˆ° {repo_id}...")
    try:
        upload_folder(
            folder_path=model_path,
            repo_id=repo_id,
            repo_type="model",
            commit_message="v3.0: FP16 Optimized (ç§»é™¤æ ‡å‡†æ–‡ä»¶,èŠ‚çœ50%ç©ºé—´)"
        )
        print("âœ… ä¸Šä¼ æˆåŠŸ!")
        print(f"ğŸŒ æ¨¡å‹é“¾æ¥: https://huggingface.co/{repo_id}")
        return True
        
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ PhotonicFusion SDXL FP16ä¼˜åŒ–å™¨")
    print("æ­¤å·¥å…·å°†åˆ é™¤æ ‡å‡†æ–‡ä»¶ï¼Œåªä¿ç•™FP16ç‰ˆæœ¬ï¼Œå¹¶é‡æ–°ä¸Šä¼ ")
    print("=" * 60)
    
    # ç¡®è®¤æ“ä½œ
    confirm = input("\nâš ï¸ è¿™å°†æ°¸ä¹…åˆ é™¤æ ‡å‡†safetensorsæ–‡ä»¶ï¼Œåªä¿ç•™FP16ç‰ˆæœ¬ã€‚ç»§ç»­å—? (y/N): ")
    if confirm.lower() != 'y':
        print("âŒ æ“ä½œå·²å–æ¶ˆ")
        return
    
    # æ­¥éª¤1: åˆ é™¤æ ‡å‡†æ–‡ä»¶
    if not delete_standard_files():
        print("âŒ åˆ é™¤æ ‡å‡†æ–‡ä»¶å¤±è´¥")
        return
    
    # æ­¥éª¤2: ä¸Šä¼ FP16ä¼˜åŒ–ç‰ˆæœ¬
    if not upload_to_huggingface_fp16_only():
        print("âŒ ä¸Šä¼ å¤±è´¥")
        return
    
    print("\nğŸ‰ FP16ä¼˜åŒ–å®Œæˆ!")
    print("æ¨¡å‹ç°åœ¨åªåŒ…å«FP16ç‰ˆæœ¬ï¼ŒèŠ‚çœäº†50%çš„å­˜å‚¨ç©ºé—´")

if __name__ == "__main__":
    main() 