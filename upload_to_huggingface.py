#!/usr/bin/env python3
"""
ä¸Šä¼ åŒ…å« fp16 variant çš„ PhotonicFusion SDXL æ¨¡å‹åˆ° HuggingFace
ä»“åº“: Baileyy/photonicfusion-sdxl
"""

import os
import sys
from pathlib import Path

def upload_to_huggingface():
    """ä¸Šä¼ æ¨¡å‹åˆ° HuggingFace Hub"""
    
    # é…ç½®
    model_path = "PhotonicFusionSDXL_V3-diffusers-manual"
    repo_id = "Baileyy/photonicfusion-sdxl"
    
    print("ğŸš€ PhotonicFusion SDXL HuggingFace ä¸Šä¼ å™¨")
    print("=" * 55)
    print(f"ğŸ“ æœ¬åœ°æ¨¡å‹: {model_path}")
    print(f"ğŸŒ HuggingFace ä»“åº“: {repo_id}")
    
    # æ£€æŸ¥æ¨¡å‹ç›®å½•
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_path}")
        return False
    
    # æ£€æŸ¥ huggingface_hub æ˜¯å¦å®‰è£…
    try:
        from huggingface_hub import HfApi, upload_folder, login
        print("âœ… huggingface_hub å¯ç”¨")
    except ImportError:
        print("âŒ huggingface_hub æœªå®‰è£…")
        print("è¯·è¿è¡Œ: pip install huggingface_hub")
        return False
    
    # éªŒè¯æ¨¡å‹æ–‡ä»¶
    print("\nğŸ” éªŒè¯æ¨¡å‹æ–‡ä»¶...")
    
    required_files = [
        "model_index.json",
        "text_encoder/model.safetensors",
        "text_encoder/model.fp16.safetensors",
        "text_encoder_2/model.safetensors", 
        "text_encoder_2/model.fp16.safetensors",
        "unet/config.json",
        "unet/diffusion_pytorch_model.safetensors",
        "unet/diffusion_pytorch_model.fp16.safetensors",
        "vae/config.json",
        "vae/diffusion_pytorch_model.safetensors",
        "vae/diffusion_pytorch_model.fp16.safetensors",
        "scheduler/scheduler_config.json"
    ]
    
    missing_files = []
    total_size = 0
    
    for file in required_files:
        file_path = os.path.join(model_path, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path)
            total_size += size
            size_mb = size / (1024 * 1024)
            
            # åŒºåˆ† fp16 å’Œæ ‡å‡†æ–‡ä»¶
            file_type = "fp16" if "fp16" in file else "standard"
            print(f"   âœ… {file} ({size_mb:.1f} MB) [{file_type}]")
        else:
            print(f"   âŒ {file}")
            missing_files.append(file)
    
    print(f"\nğŸ“Š æ¨¡å‹æ€»å¤§å°: {total_size / (1024**3):.2f} GB")
    
    if missing_files:
        print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {missing_files}")
        return False
    
    # åˆ›å»ºæ›´æ–°çš„ README
    readme_content = """---
license: apache-2.0
language:
- en
library_name: diffusers
pipeline_tag: text-to-image
tags:
- stable-diffusion-xl
- sdxl
- text-to-image
- diffusers
- fp16
---

# PhotonicFusion SDXL V3

PhotonicFusion SDXL V3 æ˜¯ä¸€ä¸ªåŸºäº Stable Diffusion XL çš„é«˜è´¨é‡å›¾åƒç”Ÿæˆæ¨¡å‹ã€‚

## æ¨¡å‹ç‰¹æ€§

- **æ¶æ„**: Stable Diffusion XL
- **åˆ†è¾¨ç‡**: 1024x1024 (åŸç”Ÿ)
- **ç²¾åº¦æ”¯æŒ**: FP16 + FP32
- **ä¼˜åŒ–**: åŒ…å« FP16 variant æ–‡ä»¶ï¼Œæ”¯æŒæ›´å¿«çš„æ¨ç†é€Ÿåº¦

## æ–‡ä»¶ç»“æ„

æ­¤ä»“åº“åŒ…å«å®Œæ•´çš„ diffusers æ ¼å¼æ¨¡å‹ï¼ŒåŒ…æ‹¬ï¼š

### æ ‡å‡†æ–‡ä»¶
- `text_encoder/model.safetensors` (246MB)
- `text_encoder_2/model.safetensors` (1.3GB) 
- `unet/diffusion_pytorch_model.safetensors` (4.9GB)
- `vae/diffusion_pytorch_model.safetensors` (159MB)

### FP16 Variant æ–‡ä»¶ ğŸ†•
- `text_encoder/model.fp16.safetensors` (246MB)
- `text_encoder_2/model.fp16.safetensors` (1.3GB)
- `unet/diffusion_pytorch_model.fp16.safetensors` (4.9GB) 
- `vae/diffusion_pytorch_model.fp16.safetensors` (159MB)

## ä½¿ç”¨æ–¹æ³•

### æ ‡å‡†åŠ è½½
```python
from diffusers import StableDiffusionXLPipeline
import torch

pipeline = StableDiffusionXLPipeline.from_pretrained(
    "Baileyy/photonicfusion-sdxl",
    torch_dtype=torch.float16,
    use_safetensors=True
)
pipeline.to("cuda")

# ç”Ÿæˆå›¾åƒ
image = pipeline(
    "a beautiful sunset over mountains, photorealistic", 
    height=1024, 
    width=1024,
    num_inference_steps=20
).images[0]
```

### FP16 Variant åŠ è½½ (æ¨è)
```python
pipeline = StableDiffusionXLPipeline.from_pretrained(
    "Baileyy/photonicfusion-sdxl",
    torch_dtype=torch.float16,
    variant="fp16",  # ä½¿ç”¨ fp16 variant
    use_safetensors=True
)
```

## æ€§èƒ½

- **æ¨ç†é€Ÿåº¦**: 2-4 ç§’ (1024x1024, RTX 4090)
- **å†…å­˜éœ€æ±‚**: ~8GB VRAM (FP16)
- **æœ€ä½³å®è·µ**: ä½¿ç”¨ FP16 variant è·å¾—æœ€ä½³æ€§èƒ½

## RunPod éƒ¨ç½²

æ­¤æ¨¡å‹å·²é’ˆå¯¹ RunPod Serverless éƒ¨ç½²è¿›è¡Œä¼˜åŒ–ï¼Œæ”¯æŒï¼š
- Volume æŒ‚è½½ä¼˜åŒ–
- FP16 è‡ªåŠ¨é™çº§
- å†…å­˜æ•ˆç‡ä¼˜åŒ–

éƒ¨ç½²ä»“åº“: [dwcqwcqw/Baileyy-photonicfusion-sdxl](https://github.com/dwcqwcqw/Baileyy-photonicfusion-sdxl)

## æ›´æ–°å†å²

### v2.0 (2025-06-25)
- âœ… æ·»åŠ  FP16 variant æ”¯æŒ
- âœ… ä¼˜åŒ–æ¨ç†æ€§èƒ½
- âœ… æ”¹è¿› RunPod å…¼å®¹æ€§
- âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†

### v1.0 (2025-06-24)
- åˆå§‹å‘å¸ƒ
- Diffusers æ ¼å¼è½¬æ¢
- åŸºç¡€åŠŸèƒ½æ”¯æŒ

## è®¸å¯è¯

Apache 2.0 License
"""
    
    # ä¿å­˜ README
    readme_path = os.path.join(model_path, "README.md")
    with open(readme_path, 'w', encoding='utf-8') as f:
        f.write(readme_content)
    print("âœ… æ›´æ–°äº† README.md")
    
    # ç™»å½• HuggingFace (éœ€è¦ç”¨æˆ·æ‰‹åŠ¨è®¾ç½® token)
    print("\nğŸ” HuggingFace èº«ä»½éªŒè¯...")
    try:
        # å°è¯•ä½¿ç”¨ç°æœ‰ token
        api = HfApi()
        user_info = api.whoami()
        print(f"âœ… å·²ç™»å½•ä¸º: {user_info['name']}")
    except Exception as e:
        print("âš ï¸ éœ€è¦ HuggingFace token")
        print("è¯·è¿è¡Œ: huggingface-cli login")
        print("æˆ–è®¾ç½®ç¯å¢ƒå˜é‡: export HUGGINGFACE_HUB_TOKEN=your_token")
        return False
    
    # ä¸Šä¼ åˆ° HuggingFace
    print(f"\nğŸ“¤ å¼€å§‹ä¸Šä¼ åˆ° {repo_id}...")
    print("âš ï¸ æ³¨æ„: ä¸Šä¼ å¤§çº¦ 13GB æ•°æ®ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
    
    try:
        # ä½¿ç”¨ upload_folder ä¸Šä¼ æ•´ä¸ªç›®å½•
        result = upload_folder(
            folder_path=model_path,
            repo_id=repo_id,
            repo_type="model",
            commit_message="Update with FP16 variant support - v2.0",
            ignore_patterns=[".DS_Store", "*.pyc", "__pycache__", "test_*.py"]
        )
        
        print(f"âœ… ä¸Šä¼ æˆåŠŸ!")
        print(f"ğŸŒ ä»“åº“åœ°å€: https://huggingface.co/{repo_id}")
        print(f"ğŸ“‹ Commit: {result}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥: {str(e)}")
        print("\nğŸ”§ æ•…éšœæ’é™¤:")
        print("1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        print("2. ç¡®è®¤ HuggingFace token æœ‰æ•ˆ")
        print("3. ç¡®è®¤å¯¹ä»“åº“æœ‰å†™å…¥æƒé™")
        return False

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥ Python ç‰ˆæœ¬
    python_version = sys.version_info
    print(f"ğŸ Python: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ£€æŸ¥å¯ç”¨ç£ç›˜ç©ºé—´
    import shutil
    free_space = shutil.disk_usage('.').free
    free_gb = free_space / (1024**3)
    print(f"ğŸ’¾ å¯ç”¨ç£ç›˜ç©ºé—´: {free_gb:.1f} GB")
    
    if free_gb < 15:
        print("âš ï¸ ç£ç›˜ç©ºé—´å¯èƒ½ä¸è¶³ï¼Œå»ºè®®è‡³å°‘ 15GB å¯ç”¨ç©ºé—´")
    
    # æ£€æŸ¥ç½‘ç»œè¿æ¥
    try:
        import urllib.request
        urllib.request.urlopen('https://huggingface.co', timeout=5)
        print("ğŸŒ ç½‘ç»œè¿æ¥: æ­£å¸¸")
    except:
        print("âŒ ç½‘ç»œè¿æ¥: å¤±è´¥")
        return False
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥")
        return False
    
    success = upload_to_huggingface()
    
    if success:
        print("\nğŸ‰ æ¨¡å‹ä¸Šä¼ å®Œæˆ!")
        print("\nğŸ“‹ éªŒè¯æ­¥éª¤:")
        print("1. è®¿é—® https://huggingface.co/Baileyy/photonicfusion-sdxl")
        print("2. æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦ä¸Šä¼ æˆåŠŸ")
        print("3. æµ‹è¯•æ¨¡å‹åŠ è½½å’Œæ¨ç†")
        print("\nğŸ’¡ ä½¿ç”¨ç¤ºä¾‹:")
        print("pipeline = StableDiffusionXLPipeline.from_pretrained('Baileyy/photonicfusion-sdxl', variant='fp16')")
    else:
        print("\nâŒ ä¸Šä¼ å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 