#!/usr/bin/env python3
"""
RunPod Volume æ¨¡å‹ä¿®å¤è„šæœ¬
ä¸“é—¨è§£å†³ "expected str, bytes or os.PathLike object, not NoneType" é”™è¯¯

ä½¿ç”¨æ–¹æ³•:
python fix_volume_model.py
"""

import os
import json
import sys

def fix_model_index(volume_path):
    """ä¿®å¤ model_index.json ä¸­çš„ None å€¼"""
    model_index_path = os.path.join(volume_path, "model_index.json")
    
    print(f"ğŸ” æ£€æŸ¥ {model_index_path}")
    
    if not os.path.exists(model_index_path):
        print(f"âŒ model_index.json ä¸å­˜åœ¨")
        return False
    
    try:
        # è¯»å–ç°æœ‰æ–‡ä»¶
        with open(model_index_path, 'r') as f:
            model_index = json.load(f)
        
        print(f"ğŸ“‹ å½“å‰ç»„ä»¶æ˜ å°„:")
        
        # æ£€æŸ¥å¹¶ä¿®å¤ None å€¼
        fixed = False
        for key, value in model_index.items():
            if not key.startswith('_') and isinstance(value, list) and len(value) >= 2:
                component_type, component_name = value[0], value[1]
                
                if component_name is None or component_name == "null":
                    print(f"âš ï¸  {key}: {component_type} -> None (éœ€è¦ä¿®å¤)")
                    
                    # è‡ªåŠ¨ä¿®å¤ç­–ç•¥
                    if key == "feature_extractor":
                        model_index[key] = ["transformers", "CLIPImageProcessor"]
                        fixed = True
                        print(f"ğŸ”§ ä¿®å¤: {key} -> CLIPImageProcessor")
                    elif key == "image_encoder": 
                        model_index[key] = ["transformers", "CLIPVisionModelWithProjection"]
                        fixed = True
                        print(f"ğŸ”§ ä¿®å¤: {key} -> CLIPVisionModelWithProjection")
                    elif key == "safety_checker":
                        model_index[key] = [None, None]
                        print(f"ğŸ”§ è®¾ç½®: {key} -> null (ç¦ç”¨å®‰å…¨æ£€æŸ¥)")
                    else:
                        print(f"â“ æœªçŸ¥ç»„ä»¶: {key} (è·³è¿‡)")
                else:
                    print(f"âœ… {key}: {component_type} -> {component_name}")
        
        # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
        if fixed:
            # å¤‡ä»½åŸæ–‡ä»¶
            backup_path = model_index_path + ".backup"
            os.rename(model_index_path, backup_path)
            print(f"ğŸ’¾ å¤‡ä»½: {backup_path}")
            
            # ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶
            with open(model_index_path, 'w') as f:
                json.dump(model_index, f, indent=2)
            print(f"âœ… ä¿å­˜ä¿®å¤åçš„ model_index.json")
            return True
        else:
            print(f"â„¹ï¸  æ— éœ€ä¿®å¤")
            return True
            
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return False

def create_missing_configs(volume_path):
    """åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶"""
    configs = {
        "tokenizer/tokenizer_config.json": {
            "add_prefix_space": False,
            "bos_token": {"__type": "AddedToken", "content": "<|startoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "clean_up_tokenization_spaces": True,
            "do_lower_case": True,
            "eos_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "errors": "replace",
            "model_max_length": 77,
            "name_or_path": "openai/clip-vit-large-patch14",
            "pad_token": "<|endoftext|>",
            "tokenizer_class": "CLIPTokenizer",
            "unk_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False}
        },
        
        "tokenizer_2/tokenizer_config.json": {
            "add_prefix_space": False,
            "bos_token": {"__type": "AddedToken", "content": "<|startoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "clean_up_tokenization_spaces": True,
            "do_lower_case": True,
            "eos_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False},
            "errors": "replace",
            "model_max_length": 77,
            "name_or_path": "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k",
            "pad_token": "<|endoftext|>",
            "tokenizer_class": "CLIPTokenizer",
            "unk_token": {"__type": "AddedToken", "content": "<|endoftext|>", "lstrip": False, "normalized": True, "rstrip": False, "single_word": False}
        },
        
        "scheduler/scheduler_config.json": {
            "_class_name": "EulerDiscreteScheduler",
            "_diffusers_version": "0.21.0",
            "beta_end": 0.012,
            "beta_schedule": "scaled_linear", 
            "beta_start": 0.00085,
            "clip_sample": False,
            "num_train_timesteps": 1000,
            "prediction_type": "epsilon",
            "sample_max_value": 1.0,
            "set_alpha_to_one": False,
            "skip_prk_steps": True,
            "steps_offset": 1,
            "timestep_spacing": "leading",
            "trained_betas": None,
            "use_karras_sigmas": False
        }
    }
    
    print(f"\nğŸ”§ æ£€æŸ¥å¹¶åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶:")
    created_count = 0
    
    for config_path, config_content in configs.items():
        full_path = os.path.join(volume_path, config_path)
        
        if not os.path.exists(full_path):
            try:
                os.makedirs(os.path.dirname(full_path), exist_ok=True)
                with open(full_path, 'w') as f:
                    json.dump(config_content, f, indent=2)
                print(f"âœ… åˆ›å»º: {config_path}")
                created_count += 1
            except Exception as e:
                print(f"âŒ åˆ›å»º {config_path} å¤±è´¥: {e}")
        else:
            print(f"â­ï¸  å·²å­˜åœ¨: {config_path}")
    
    return created_count

def main():
    """ä¸»å‡½æ•°"""
    volume_path = "/runpod-volume/photonicfusion-sdxl"
    
    print("ğŸš€ RunPod Volume æ¨¡å‹ä¿®å¤å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥Volumeè·¯å¾„
    if not os.path.exists(volume_path):
        print(f"âŒ Volumeè·¯å¾„ä¸å­˜åœ¨: {volume_path}")
        print("è¯·ç¡®ä¿æ¨¡å‹å·²æ­£ç¡®ä¸Šä¼ åˆ°Volume")
        sys.exit(1)
    
    print(f"ğŸ“‚ Volumeè·¯å¾„: {volume_path}")
    
    # æ£€æŸ¥å¿…éœ€ç»„ä»¶
    required_components = ["model_index.json", "unet", "vae", "text_encoder", "text_encoder_2"]
    missing_components = []
    
    print(f"\nğŸ“‹ æ£€æŸ¥å¿…éœ€ç»„ä»¶:")
    for component in required_components:
        component_path = os.path.join(volume_path, component)
        if os.path.exists(component_path):
            if os.path.isdir(component_path):
                file_count = len(os.listdir(component_path))
                print(f"âœ… {component}/ ({file_count} æ–‡ä»¶)")
            else:
                print(f"âœ… {component}")
        else:
            print(f"âŒ {component} (ç¼ºå¤±)")
            missing_components.append(component)
    
    if missing_components:
        print(f"\nâŒ å…³é”®ç»„ä»¶ç¼ºå¤±: {missing_components}")
        print("è¯·é‡æ–°ä¸Šä¼ å®Œæ•´çš„æ¨¡å‹æ–‡ä»¶")
        sys.exit(1)
    
    # ä¿®å¤ model_index.json
    print(f"\nğŸ”§ ä¿®å¤ model_index.json:")
    if not fix_model_index(volume_path):
        print("âŒ model_index.json ä¿®å¤å¤±è´¥")
        sys.exit(1)
    
    # åˆ›å»ºç¼ºå¤±çš„é…ç½®æ–‡ä»¶
    created = create_missing_configs(volume_path)
    
    # æ€»ç»“
    print(f"\nğŸ“Š ä¿®å¤æ€»ç»“:")
    print(f"âœ… model_index.json: å·²æ£€æŸ¥å¹¶ä¿®å¤")
    print(f"âœ… é…ç½®æ–‡ä»¶: åˆ›å»ºäº† {created} ä¸ª")
    
    print(f"\nğŸ‰ ä¿®å¤å®Œæˆ! ç°åœ¨å¯ä»¥é‡å¯æ‚¨çš„RunPodå®ä¾‹äº†")

if __name__ == "__main__":
    main() 