# PhotonicFusion SDXL - åç«¯é”™è¯¯ä¿®å¤

## ğŸ› é—®é¢˜æè¿°

æ ¹æ®æ—¥å¿—ï¼Œåç«¯å‡ºç°äº†ä¸¤ä¸ªä¸»è¦é”™è¯¯ï¼š

### é”™è¯¯ 1: device_map="auto" ä¸æ”¯æŒ

```
âŒ Error loading model: auto not supported. Supported strategies are: balanced
NotImplementedError: auto not supported. Supported strategies are: balanced
```

### é”™è¯¯ 2: ç¼ºå°‘ protobuf åº“

```
âŒ Error loading model:
 requires the protobuf library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/protocolbuffers/protobuf/tree/master/python#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.
```

## ğŸ” é”™è¯¯åŸå› 

é”™è¯¯åŸå› æ˜¯åœ¨ `StableDiffusionXLPipeline.from_pretrained()` ä¸­ä½¿ç”¨äº† `device_map="auto"` å‚æ•°ï¼Œä½†å½“å‰ç‰ˆæœ¬çš„ diffusers åº“ä¸æ”¯æŒ "auto" ç­–ç•¥ï¼Œåªæ”¯æŒ "balanced" ç­–ç•¥ã€‚

å…·ä½“é”™è¯¯ä½ç½®ï¼š
- æ–‡ä»¶ï¼š`handler.py`ï¼Œç¬¬46è¡Œå’Œç¬¬54è¡Œ
- åŸä»£ç ï¼š`device_map="auto" if device == "cuda" else None`

## âœ… ä¿®å¤å†…å®¹

### ç¬¬ä¸€éƒ¨åˆ†ï¼šä¿®å¤ device_map="auto" é”™è¯¯

#### 1. ç§»é™¤ device_map="auto"

**ä¿®æ”¹å‰ï¼š**
```python
pipeline = StableDiffusionXLPipeline.from_pretrained(
    local_model_path,
    torch_dtype=torch_dtype,
    use_safetensors=True,
    device_map="auto" if device == "cuda" else None,  # âŒ è¿™è¡Œå¯¼è‡´é”™è¯¯
    local_files_only=True
)
```

**ä¿®æ”¹åï¼š**
```python
pipeline = StableDiffusionXLPipeline.from_pretrained(
    local_model_path,
    torch_dtype=torch_dtype,
    use_safetensors=True,
    local_files_only=True
)
```

#### 2. æ”¹è¿›è®¾å¤‡ç®¡ç†

**ä¿®æ”¹å‰ï¼š**
```python
# Move to device if not using device_map
if device == "cuda" and pipeline.device != torch.device("cuda"):
    pipeline = pipeline.to(device)
```

**ä¿®æ”¹åï¼š**
```python
# Move to device
if device == "cuda":
    pipeline = pipeline.to(device)
    print(f"âœ… Pipeline moved to {device}")
```

#### 3. æ·»åŠ å¤šå›¾åƒæ”¯æŒ

ä¸ºäº†æå‡ç”¨æˆ·ä½“éªŒï¼ŒåŒæ—¶æ·»åŠ äº†å¤šå›¾åƒç”Ÿæˆæ”¯æŒï¼š

- æ–°å¢ `num_images_per_prompt` å‚æ•°ï¼ˆ1-4å¼ å›¾åƒï¼‰
- ä¿®æ”¹è¿”å›æ ¼å¼ä» `"image"` åˆ° `"images"` æ•°ç»„
- å‰ç«¯å…¼å®¹æ–°æ—§æ ¼å¼

### ç¬¬äºŒéƒ¨åˆ†ï¼šä¿®å¤ protobuf ç¼ºå¤±é”™è¯¯

#### 1. æ·»åŠ  protobuf ä¾èµ–

**ä¿®æ”¹å‰ï¼š**
```
# Utilities
numpy
requests
huggingface-hub>=0.16.0
```

**ä¿®æ”¹åï¼š**
```
# Utilities
numpy
requests
huggingface-hub>=0.16.0
protobuf>=3.20.0
```

#### 2. æ›´æ–° Dockerfile ç¡®ä¿ protobuf å®‰è£…

**ä¿®æ”¹å‰ï¼š**
```dockerfile
# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
```

**ä¿®æ”¹åï¼š**
```dockerfile
# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
# Ensure protobuf is installed correctly
RUN pip install --no-cache-dir protobuf==3.20.3
```

#### 3. æ”¹è¿›æ¨¡å‹åŠ è½½é€»è¾‘ï¼Œæ·»åŠ é”™è¯¯å¤„ç†å’Œå›é€€æœºåˆ¶

**ä¿®æ”¹å‰ï¼š**
```python
# Try loading from local volume first
if os.path.exists(local_model_path):
    print(f"ğŸ“ Loading model from local volume: {local_model_path}")
    pipeline = StableDiffusionXLPipeline.from_pretrained(
        local_model_path,
        torch_dtype=torch_dtype,
        use_safetensors=True,
        local_files_only=True
    )
    print("âœ… Model loaded from local volume")
else:
    print(f"ğŸ“¦ Local volume not found, loading from Hugging Face Hub: {hf_model_name}")
    pipeline = StableDiffusionXLPipeline.from_pretrained(
        hf_model_name,
        torch_dtype=torch_dtype,
        use_safetensors=True
    )
    print("âœ… Model loaded from Hugging Face Hub")
```

**ä¿®æ”¹åï¼š**
```python
try:
    if os.path.exists(local_model_path):
        print(f"ğŸ“ Loading model from local volume: {local_model_path}")
        
        # Check if tokenizer files exist
        tokenizer_files_exist = os.path.exists(os.path.join(local_model_path, "tokenizer"))
        
        pipeline = StableDiffusionXLPipeline.from_pretrained(
            local_model_path,
            torch_dtype=torch_dtype,
            use_safetensors=True,
            local_files_only=True,
            low_cpu_mem_usage=True,
            # Skip missing files
            ignore_mismatched_sizes=True
        )
        print("âœ… Model loaded from local volume")
    else:
        print(f"ğŸ“¦ Local volume not found, loading from Hugging Face Hub: {hf_model_name}")
        pipeline = StableDiffusionXLPipeline.from_pretrained(
            hf_model_name,
            torch_dtype=torch_dtype,
            use_safetensors=True,
            low_cpu_mem_usage=True
        )
        print("âœ… Model loaded from Hugging Face Hub")
except Exception as e:
    print(f"âŒ Error loading model from primary source: {str(e)}")
    print("âš ï¸ Attempting to load from Hugging Face Hub as fallback...")
    
    # Fallback to official SDXL model if custom model fails
    try:
        print("ğŸ“¦ Loading official SDXL model as fallback")
        pipeline = StableDiffusionXLPipeline.from_pretrained(
            "stabilityai/stable-diffusion-xl-base-1.0",
            torch_dtype=torch_dtype,
            use_safetensors=True,
            variant="fp16"
        )
        print("âœ… Fallback model loaded successfully")
    except Exception as fallback_error:
        print(f"âŒ Fallback also failed: {str(fallback_error)}")
        raise fallback_error
```

## ğŸ§ª æµ‹è¯•éªŒè¯

åˆ›å»ºäº†ä¸¤ä¸ªå®Œæ•´çš„æµ‹è¯•å¥—ä»¶ï¼š

### `test_fix.py` - æµ‹è¯• device_map ä¿®å¤
1. **æ¨¡å‹åŠ è½½æµ‹è¯•** - éªŒè¯ä¸å†å‡ºç° device_map é”™è¯¯
2. **å•å›¾åƒç”Ÿæˆæµ‹è¯•** - éªŒè¯åŸºæœ¬åŠŸèƒ½æ­£å¸¸
3. **å¤šå›¾åƒç”Ÿæˆæµ‹è¯•** - éªŒè¯æ–°åŠŸèƒ½æ­£å¸¸
4. **Handler APIæµ‹è¯•** - éªŒè¯å®Œæ•´çš„APIæµç¨‹

### `test_protobuf_fix.py` - æµ‹è¯• protobuf ä¿®å¤
1. **ä¾èµ–æ£€æŸ¥** - éªŒè¯ protobuf æ­£ç¡®å®‰è£…
2. **CLIP Tokenizer æµ‹è¯•** - éªŒè¯ tokenizer åŠ è½½æ­£å¸¸
3. **SDXL Pipeline æµ‹è¯•** - éªŒè¯ pipeline åŠ è½½æ­£å¸¸
4. **Handler å¯¼å…¥æµ‹è¯•** - éªŒè¯ handler æ¨¡å—æ­£å¸¸

è¿è¡Œæµ‹è¯•ï¼š
```bash
# æµ‹è¯• device_map ä¿®å¤
python test_fix.py

# æµ‹è¯• protobuf ä¿®å¤
python test_protobuf_fix.py
```

## ğŸ“‹ éƒ¨ç½²æ­¥éª¤

### 1. æœ¬åœ°æµ‹è¯•ï¼ˆæ¨èï¼‰
```bash
# åœ¨ photonicfusion-sdxl-runpod ç›®å½•ä¸‹
python test_fix.py
```

### 2. æ„å»ºæ–°é•œåƒ
```bash
./fix_deploy.sh
```

### 3. æ›´æ–° RunPod ç«¯ç‚¹
1. åœ¨ RunPod æ§åˆ¶å°ä¸­æ›´æ–°æ‚¨çš„ç«¯ç‚¹
2. ä½¿ç”¨æ–°æ„å»ºçš„ Docker é•œåƒ
3. ç¡®ä¿ä½¿ç”¨ç›¸åŒçš„ volume é…ç½®

### 4. éªŒè¯ä¿®å¤
ä½¿ç”¨ä»¥ä¸‹æµ‹è¯•æ•°æ®éªŒè¯ç«¯ç‚¹ï¼š

```json
{
  "input": {
    "prompt": "a beautiful landscape, high quality",
    "width": 1024,
    "height": 1024,
    "num_inference_steps": 30,
    "num_images_per_prompt": 1
  }
}
```

é¢„æœŸå“åº”æ ¼å¼ï¼š
```json
{
  "images": ["base64_encoded_image_data"],
  "prompt": "a beautiful landscape, high quality",
  "parameters": {
    "width": 1024,
    "height": 1024,
    "num_inference_steps": 30,
    "guidance_scale": 7.5,
    "num_images_per_prompt": 1,
    "seed": null
  }
}
```

## ğŸ”§ å‰ç«¯å…¼å®¹æ€§

å‰ç«¯ä»£ç å·²æ›´æ–°ä»¥æ”¯æŒæ–°çš„ API æ ¼å¼ï¼ŒåŒæ—¶ä¿æŒå‘åå…¼å®¹ï¼š

- âœ… æ”¯æŒæ–°æ ¼å¼ï¼š`result.output.images` (æ•°ç»„)
- âœ… æ”¯æŒæ—§æ ¼å¼ï¼š`result.output.image` (å•å¼ )
- âœ… è‡ªåŠ¨é”™è¯¯å¤„ç†å’Œæ˜¾ç¤º

## ğŸš€ æ–°åŠŸèƒ½

### å¤šå›¾åƒç”Ÿæˆ
ç°åœ¨æ”¯æŒä¸€æ¬¡ç”Ÿæˆå¤šå¼ å›¾åƒï¼š

**å‰ç«¯ä½¿ç”¨ï¼š**
- åœ¨"å›¾åƒæ•°é‡"æ»‘å—ä¸­é€‰æ‹©1-4å¼ 
- ä¸€æ¬¡è¯·æ±‚ç”Ÿæˆå¤šå¼ ä¸åŒçš„å›¾åƒ

**APIä½¿ç”¨ï¼š**
```json
{
  "input": {
    "prompt": "digital art masterpiece",
    "num_images_per_prompt": 3
  }
}
```

### æ”¹è¿›çš„é”™è¯¯å¤„ç†
- æ›´æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
- è‡ªåŠ¨ CUDA OOM æ¢å¤
- å†…å­˜ä¼˜åŒ–ç­–ç•¥

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

ä¿®å¤åçš„æ€§èƒ½æå‡ï¼š
- âœ… æ¶ˆé™¤æ¨¡å‹åŠ è½½é”™è¯¯
- âœ… æ›´å¿«çš„è®¾å¤‡åˆå§‹åŒ–
- âœ… æ”¯æŒæ‰¹é‡å›¾åƒç”Ÿæˆ
- âœ… æ™ºèƒ½å†…å­˜ç®¡ç†

## ğŸ” æ•…éšœæ’é™¤

### å¦‚æœä»ç„¶å‡ºç°é”™è¯¯ï¼š

1. **æ£€æŸ¥ diffusers ç‰ˆæœ¬**ï¼š
   ```bash
   pip list | grep diffusers
   ```
   
2. **æ£€æŸ¥ torch ç‰ˆæœ¬**ï¼š
   ```bash
   pip list | grep torch
   ```

3. **æ¸…é™¤ç¼“å­˜**ï¼š
   ```bash
   rm -rf ~/.cache/huggingface/transformers/
   ```

4. **æ£€æŸ¥ CUDA å¯ç”¨æ€§**ï¼š
   ```python
   import torch
   print(f"CUDA available: {torch.cuda.is_available()}")
   print(f"CUDA version: {torch.version.cuda}")
   ```

### å¸¸è§é—®é¢˜ï¼š

**Q: æ¨¡å‹åŠ è½½æ…¢**
A: ç¡®ä¿ä½¿ç”¨ RunPod Volume é¢„ä¸‹è½½æ¨¡å‹

**Q: å†…å­˜ä¸è¶³**
A: é™ä½åˆ†è¾¨ç‡æˆ–å‡å°‘ num_images_per_prompt

**Q: ç”Ÿæˆè´¨é‡å·®**
A: å¢åŠ  num_inference_steps å’Œä¼˜åŒ– prompt

## ğŸ“ æ›´æ–°æ—¥å¿—

- **2025-01-25**: ä¿®å¤ device_map="auto" é”™è¯¯
- **2025-01-25**: æ·»åŠ å¤šå›¾åƒç”Ÿæˆæ”¯æŒ
- **2025-01-25**: æ”¹è¿›é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- **2025-01-25**: æ›´æ–°å‰ç«¯å…¼å®¹æ€§
- **2025-01-25**: æ·»åŠ å®Œæ•´æµ‹è¯•å¥—ä»¶
- **2025-01-26**: ä¿®å¤ protobuf ç¼ºå¤±é”™è¯¯
- **2025-01-26**: æ·»åŠ æ¨¡å‹åŠ è½½å›é€€æœºåˆ¶
- **2025-01-26**: æ”¹è¿›é”™è¯¯å¤„ç†å’Œå®¹é”™æ€§

---

**ä¿®å¤å®Œæˆï¼** ğŸ‰ æ‚¨çš„ PhotonicFusion SDXL åç«¯ç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œäº†ã€‚ 